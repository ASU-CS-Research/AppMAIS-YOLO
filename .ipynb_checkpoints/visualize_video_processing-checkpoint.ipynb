{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize video processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T18:35:57.794988185Z",
     "start_time": "2023-06-27T18:35:53.843577420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: /home/olofintuyita/repos/AppMAIS-YOLO\n",
      "Python version: 3.9.16 (main, May 15 2023, 23:46:34) \n",
      "[GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from cv2 import Mat\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "HOME = os.getcwd()\n",
    "print(f\"Directory: {HOME}\")\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T18:35:58.326661155Z",
     "start_time": "2023-06-27T18:35:58.005294065Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/olofintuyita/repos/AppMAIS-YOLO/runs\\\\detect'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_folders \u001b[38;5;241m=\u001b[39m [folder \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHOME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mruns\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdetect\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m folder]\n\u001b[1;32m      2\u001b[0m most_recent_train \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(HOME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m'\u001b[39m,  train_folders[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(most_recent_train):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/olofintuyita/repos/AppMAIS-YOLO/runs\\\\detect'"
     ]
    }
   ],
   "source": [
    "train_folders = [folder for folder in os.listdir(os.path.join(HOME, 'runs\\\\detect')) if 'train' in folder]\n",
    "most_recent_train = os.path.join(HOME, 'runs', 'detect',  train_folders[-1], 'weights', 'best.pt')\n",
    "if os.path.exists(most_recent_train):\n",
    "    model = YOLO(model=most_recent_train)\n",
    "    print(model.info())\n",
    "else:\n",
    "    print(\"No pre-trained model found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to make predictions, configure the confidence threshold and optionally visualize and/or save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model: YOLO, img: Mat | str, threshold: float = 0.5, save: bool = False, show: bool = False) -> Mat | None:\n",
    "    if isinstance(img, str):\n",
    "        img = cv2.imread(img)\n",
    "\n",
    "    predictions = model.predict(img)\n",
    "    results = predictions[0]\n",
    "    bounding_boxes = results.boxes\n",
    "    height, width, channels = img.shape\n",
    "    img = cv2.resize(img, (width*2, height*2), interpolation=cv2.INTER_CUBIC)\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_RGB2RGBA)\n",
    "    workers = 0\n",
    "    drones = 0\n",
    "    for box in bounding_boxes:\n",
    "        x1, y1, x2, y2, conf, classid = box.data.tolist()[0]\n",
    "        x1 = int(x1)*2; y1 = int(y1)*2; x2 = int(x2)*2; y2 = int(y2)*2; conf = float(conf); classid = int(classid)\n",
    "        if conf < threshold:\n",
    "            continue\n",
    "        label = f'{int(conf*100)}%'\n",
    "        color = (0, 127, 200)\n",
    "        if classid == 0:\n",
    "            workers += 1\n",
    "            color = (255, 34, 134)\n",
    "        else:\n",
    "            drones += 1\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "        #fill rectangle with semi transparent color\n",
    "        overlay = img.copy()\n",
    "        cv2.rectangle(overlay, (x1, y1), (x2, y2), (0, 0, 0), -1)\n",
    "        img = cv2.addWeighted(overlay, 0.2, img, 0.8, 0)\n",
    "        \n",
    "        cv2.rectangle(img, (x1, y1-40), (x1+60, y1), color, -1)\n",
    "        cv2.putText(img, label, (x1, y1-12), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_CUBIC)\n",
    "    if save:\n",
    "        cv2.imwrite(\"result.png\", img)\n",
    "    if show:\n",
    "        # downscale image for display\n",
    "        cv2.imshow(\"Result\", img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    return (img, workers, drones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test some images to get general idea of model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = os.path.join(HOME, \"test_images\", \"1.jpg\")\n",
    "test2 = os.path.join(HOME, \"test_images\", \"2.jpg\")\n",
    "test3 = os.path.join(HOME, \"test_images\", \"3.jpg\")\n",
    "test4 = os.path.join(HOME, \"test_images\", \"4.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image(model=model, img=test1, threshold=0.5, save=True, show=True)  #This one is saved to the current directory\n",
    "predict_image(model=model, img=test2, threshold=0.5, save=False, show=True)\n",
    "predict_image(model=model, img=test3, threshold=0.5, save=False, show=True)\n",
    "predict_image(model=model, img=test4, threshold=0.5, save=False, show=True)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise a video of bees using YOLO model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_with_bounding_boxes(model: YOLO, video_path: str, output_path: str, detection_func, frames_interval: int = 10, threshold: float = 0.5):\n",
    "    df = pd.DataFrame(columns=['workers', 'drones'])\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    cap_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    print(\"Original FPS: \", cap_fps)\n",
    "    out_fps = int(cap_fps / frames_interval)\n",
    "    print(\"Output FPS: \", out_fps)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_path, fourcc, out_fps, (frame_width, frame_height))\n",
    "    frame_count = 0\n",
    "    modified_frame = None\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_count % frames_interval == 0 or modified_frame is None:\n",
    "            modified_frame, workers, drones = detection_func(model=model, img=frame, threshold=threshold, save=False, show=False)\n",
    "            df.loc[len(df)] = [workers, drones]\n",
    "            out.write(modified_frame)\n",
    "        frame_count += 1\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    df.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = \"input_video.h264\"\n",
    "process_video_with_bounding_boxes(model=model, video_path=video, output_path=\"output_video.mp4\", threshold=0.5, detection_func=predict_image, frames_interval=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the latest video results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"result.csv\")\n",
    "\n",
    "#add 5ma\n",
    "df['workers_10ma'] = df['workers'].rolling(window=10).mean()\n",
    "df['drones_10ma'] = df['drones'].rolling(window=10).mean()\n",
    "#shift back 10\n",
    "df['workers_10ma'] = df['workers_10ma'].shift(-5)\n",
    "df['drones_10ma'] = df['drones_10ma'].shift(-5)\n",
    "\n",
    "#plot workers and workers 5ma\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(df['workers_10ma'], label='drones')\n",
    "plt.plot(df['drones_10ma'], label='workers')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Drone and Worker Count')\n",
    "#draw line at average\n",
    "plt.axhline(y=df['workers_10ma'].mean(), color='r', linestyle='-', label='workers average')\n",
    "plt.axhline(y=df['drones_10ma'].mean(), color='b', linestyle='-', label='drones average')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
