{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: c:\\Users\\Thomas\\Pictures\\YOLOv3\n",
      "Python version: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2\n",
    "from cv2 import Mat\n",
    "import numpy as np\n",
    "import sys\n",
    "HOME = os.getcwd()\n",
    "print(f\"Directory: {HOME}\")\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image_path = os.path.join(HOME, \"train\", \"images\", \"0.jpg\")\n",
    "example_label_path = os.path.join(HOME, \"train\", \"labels\", \"0.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to show image in seperate window, waiting for a key to be pressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_cv2(img: Mat | str):\n",
    "    if isinstance(img, str):\n",
    "        img = cv2.imread(img)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image manipulation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_brightness(img: Mat | str, value: float):\n",
    "    if isinstance(img, str):\n",
    "        img = cv2.imread(img)\n",
    "    return cv2.convertScaleAbs(img, alpha=value, beta=0)\n",
    "\n",
    "def change_contrast(img: Mat | str, value: float):\n",
    "    if isinstance(img, str):\n",
    "        img = cv2.imread(img)\n",
    "    return cv2.convertScaleAbs(img, alpha=1.0, beta=value)\n",
    "\n",
    "def change_saturation(img: Mat | str, value: float):\n",
    "    if isinstance(img, str):\n",
    "        img = cv2.imread(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    img[:, :, 1] = img[:, :, 1] * value\n",
    "    return cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "def blur_image(img: Mat | str, kernel_size: int):\n",
    "    if isinstance(img, str):\n",
    "        img = cv2.imread(img)\n",
    "    return cv2.blur(img, (kernel_size, kernel_size))\n",
    "\n",
    "def sharpen_image(img: Mat | str):\n",
    "    if isinstance(img, str):\n",
    "        img = cv2.imread(img)\n",
    "    kernel_size = 20\n",
    "    kernel = np.zeros((kernel_size, kernel_size), np.float32)\n",
    "    kernel[int((kernel_size - 1) / 2), int((kernel_size - 1) / 2)] = 2.0\n",
    "    boxFilter = np.ones((kernel_size, kernel_size), np.float32) / float(kernel_size * kernel_size)\n",
    "    kernel = kernel - boxFilter\n",
    "    return cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "def flip_image(img: Mat | str, flip_code: str):\n",
    "    if isinstance(img, str):\n",
    "        img = cv2.imread(img)\n",
    "    if flip_code == 'horizontal':\n",
    "        return cv2.flip(img, 1)\n",
    "    elif flip_code == 'vertical':\n",
    "        return cv2.flip(img, 0)\n",
    "    elif flip_code == 'both':\n",
    "        return cv2.flip(img, -1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test image manipulation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(example_image_path)\n",
    "\n",
    "#increase brightness\n",
    "img_bright = change_brightness(img, 1.5)\n",
    "show_image_cv2(img_bright)\n",
    "\n",
    "#decrease brightness\n",
    "img_dark = change_brightness(img, 0.5)\n",
    "show_image_cv2(img_dark)\n",
    "\n",
    "#blur\n",
    "img_blur = blur_image(img, 5)\n",
    "show_image_cv2(img_blur)\n",
    "\n",
    "#sharpen\n",
    "img_sharp = sharpen_image(img)\n",
    "show_image_cv2(img_sharp)\n",
    "\n",
    "#increase saturation\n",
    "img_sat = change_saturation(img, 1.5)\n",
    "show_image_cv2(img_sat)\n",
    "\n",
    "#decrease saturation\n",
    "img_desat = change_saturation(img, 0.5)\n",
    "show_image_cv2(img_desat)\n",
    "\n",
    "#flip\n",
    "img_flip = flip_image(img, 'both')\n",
    "show_image_cv2(img_flip)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 4 random augmentation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_actions() -> list[str]:\n",
    "    brightness = ['bright', 'dark']\n",
    "    blurriness = ['blur', 'sharp']\n",
    "    saturation = ['sat', 'desat']\n",
    "    flip = ['horizontal', 'vertical', 'both']\n",
    "    actions = []\n",
    "    random_brightness = np.random.choice(brightness, 1, replace=False)[0]\n",
    "    actions.append(random_brightness)\n",
    "    random_blurriness = np.random.choice(blurriness, 1, replace=False)[0]\n",
    "    actions.append(random_blurriness)\n",
    "    random_saturation = np.random.choice(saturation, 1, replace=False)[0]\n",
    "    actions.append(random_saturation)\n",
    "    random_flip = np.random.choice(flip, 1, replace=False)[0]\n",
    "    actions.append(random_flip)\n",
    "    return actions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply augmentation effects to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_actions(img: Mat, actions: list[str]):\n",
    "    for action in actions:\n",
    "        if action == 'bright':\n",
    "            img = change_brightness(img, 1.25)\n",
    "        elif action == 'dark':\n",
    "            img = change_brightness(img, 0.75)\n",
    "        elif action == 'blur':\n",
    "            img = blur_image(img, 4)\n",
    "        elif action == 'sharp':\n",
    "            img = sharpen_image(img)\n",
    "        elif action == 'sat':\n",
    "            img = change_saturation(img, 1.25)\n",
    "        elif action == 'desat':\n",
    "            img = change_saturation(img, 0.75)\n",
    "        elif action == 'horizontal':\n",
    "            img = flip_image(img, 'horizontal')\n",
    "        elif action == 'vertical':\n",
    "            img = flip_image(img, 'vertical')\n",
    "        elif action == 'both':\n",
    "            img = flip_image(img, 'both')\n",
    "    return img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize some random data augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dark', 'sharp', 'desat', 'both']\n",
      "['bright', 'blur', 'sat', 'both']\n",
      "['dark', 'blur', 'sat', 'horizontal']\n",
      "['dark', 'blur', 'sat', 'vertical']\n",
      "['bright', 'sharp', 'desat', 'vertical']\n",
      "['bright', 'blur', 'desat', 'horizontal']\n",
      "['dark', 'blur', 'desat', 'horizontal']\n",
      "['bright', 'blur', 'sat', 'vertical']\n",
      "['bright', 'sharp', 'desat', 'horizontal']\n",
      "['bright', 'blur', 'sat', 'horizontal']\n",
      "['bright', 'blur', 'sat', 'both']\n",
      "['dark', 'sharp', 'desat', 'both']\n",
      "['dark', 'blur', 'desat', 'vertical']\n",
      "['dark', 'sharp', 'sat', 'horizontal']\n",
      "['dark', 'sharp', 'sat', 'both']\n",
      "['dark', 'blur', 'sat', 'horizontal']\n",
      "['dark', 'blur', 'sat', 'horizontal']\n",
      "['dark', 'sharp', 'sat', 'both']\n",
      "['bright', 'sharp', 'sat', 'both']\n",
      "['bright', 'sharp', 'sat', 'both']\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(example_image_path)\n",
    "for i in range(20):\n",
    "    actions = get_random_actions()\n",
    "    print(actions)\n",
    "    img2 = apply_actions(img, actions)\n",
    "    show_image_cv2(img2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw boxes on given image using it's coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(img: Mat | str, bounding_boxes: list, classes: list):\n",
    "    for i in range(len(bounding_boxes)):\n",
    "        box = bounding_boxes[i]\n",
    "        label = classes[i]\n",
    "        x1 = int(box[0])\n",
    "        y1 = int(box[1])\n",
    "        x2 = int(box[2])\n",
    "        y2 = int(box[3])\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 34, 134), 1)\n",
    "        #fill rectangle with semi transparent color\n",
    "        overlay = img.copy()\n",
    "        cv2.rectangle(overlay, (x1, y1), (x2, y2), (0, 0, 0), -1)\n",
    "        img = cv2.addWeighted(overlay, 0.2, img, 0.8, 0)\n",
    "        \n",
    "        cv2.rectangle(img, (x1, y1-20), (x1+20, y1), (255, 34, 134), -1)\n",
    "        cv2.putText(img, \" \"+label, (x1, y1-6), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = os.path.join(HOME, 'train', 'images')\n",
    "labels_path = os.path.join(HOME, 'train', 'labels')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename all files for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_names = os.listdir(images_path)\n",
    "names = [name.rstrip('.jpg') for name in images_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(names)):\n",
    "    name = names[i]\n",
    "    img_path = os.path.join(images_path, name + '.jpg')\n",
    "    lbl_path = os.path.join(labels_path, name + '.txt')\n",
    "    img_path_new = os.path.join(images_path, str(i) + '.jpg')\n",
    "    lbl_path_new = os.path.join(labels_path, str(i) + '.txt')\n",
    "    if os.path.exists(img_path) and os.path.exists(lbl_path):\n",
    "        os.rename(img_path, img_path_new)\n",
    "        os.rename(lbl_path, lbl_path_new)\n",
    "    else:\n",
    "        print('Error: ' + name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display top of the annotated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = os.listdir(images_path)\n",
    "for i in range(10):\n",
    "    img_path = os.path.join(images_path, names[i])\n",
    "    lbl_path = os.path.join(labels_path, names[i].rstrip('.jpg') + '.txt')\n",
    "    with open(lbl_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    bounding_boxes = []\n",
    "    classes = []\n",
    "    for line in lines:\n",
    "        line = line.strip().split(' ')\n",
    "        classes.append(line[0])\n",
    "        xc = float(line[1]); yc = float(line[2]); xw = float(line[3]); yw = float(line[4])\n",
    "        x1 = int((xc - xw/2) * 640); y1 = int((yc - yw/2) * 480); x2 = int((xc + xw/2) * 640); y2 = int((yc + yw/2) * 480)\n",
    "        bounding_boxes.append([x1, y1, x2, y2])\n",
    "    img = cv2.imread(img_path)\n",
    "    img = draw_boxes(img, bounding_boxes, classes)\n",
    "    show_image_cv2(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test bounding box transformation when image is flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_flip = 'both'\n",
    "\n",
    "img = cv2.imread(example_image_path)\n",
    "img = flip_image(img, type_of_flip)\n",
    "\n",
    "with open(example_label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "bounding_boxes = []\n",
    "classes = []\n",
    "for line in lines:\n",
    "    line = line.strip().split(' ')\n",
    "    classes.append(line[0])\n",
    "    xc = float(line[1]); yc = float(line[2]); xw = float(line[3]); yw = float(line[4])\n",
    "    if type_of_flip == 'horizontal':\n",
    "        xc = 1 - xc\n",
    "    elif type_of_flip == 'vertical':\n",
    "        yc = 1 - yc\n",
    "    elif type_of_flip == 'both':\n",
    "        xc = 1 - xc; yc = 1 - yc\n",
    "    x1 = int((xc - xw/2) * 640); y1 = int((yc - yw/2) * 480); x2 = int((xc + xw/2) * 640); y2 = int((yc + yw/2) * 480)\n",
    "    bounding_boxes.append([x1, y1, x2, y2])\n",
    "img = draw_boxes(img, bounding_boxes, classes)\n",
    "show_image_cv2(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment 2 images for each image in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = os.path.join(HOME, 'valid', 'images')\n",
    "labels_path = os.path.join(HOME, 'valid', 'labels')\n",
    "\n",
    "images_names = os.listdir(images_path)\n",
    "names = [name.rstrip('.jpg') for name in images_names]\n",
    "\n",
    "for i in range(len(names)):\n",
    "    name = names[i]\n",
    "    img_path = os.path.join(images_path, name + '.jpg')\n",
    "    lbl_path = os.path.join(labels_path, name + '.txt')\n",
    "    if os.path.exists(img_path) and os.path.exists(lbl_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        with open(lbl_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        bounding_boxes = []\n",
    "        classes = []\n",
    "        for line in lines:\n",
    "            line = line.strip().split(' ')\n",
    "            classes.append(line[0])\n",
    "            xc = float(line[1]); yc = float(line[2]); xw = float(line[3]); yw = float(line[4])\n",
    "            x1 = int((xc - xw/2) * 640); y1 = int((yc - yw/2) * 480); x2 = int((xc + xw/2) * 640); y2 = int((yc + yw/2) * 480)\n",
    "            bounding_boxes.append([x1, y1, x2, y2])\n",
    "        for j in range(2):\n",
    "            actions = get_random_actions()\n",
    "            img2 = apply_actions(img, actions)\n",
    "            img2_path = os.path.join(images_path, f\"{i}_{j}.jpg\")\n",
    "            img2 = cv2.imwrite(img2_path, img2)\n",
    "            with open(os.path.join(labels_path, f\"{i}_{j}.txt\"), 'w') as f:\n",
    "                for k in range(len(classes)):\n",
    "                    x1 = bounding_boxes[k][0]; y1 = bounding_boxes[k][1]; x2 = bounding_boxes[k][2]; y2 = bounding_boxes[k][3]\n",
    "                    xc = (x1 + x2) / 2 / 640; yc = (y1 + y2) / 2 / 480; xw = (x2 - x1) / 640; yw = (y2 - y1) / 480\n",
    "                    if 'horizontal' in actions:\n",
    "                        xc = 1 - xc\n",
    "                    elif 'vertical' in actions:\n",
    "                        yc = 1 - yc\n",
    "                    elif 'both' in actions:\n",
    "                        xc = 1 - xc; yc = 1 - yc\n",
    "                    f.write(f\"{classes[k]} {xc} {yc} {xw} {yw}\\n\")\n",
    "    else:\n",
    "        print('Error: ' + name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
